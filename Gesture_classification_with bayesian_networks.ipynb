{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Gaussian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton definition\n",
    "NUI_SKELETON_POSITION_COUNT = 20\n",
    "\n",
    "NONE = -1\n",
    "HIP_CENTER = 0\n",
    "SPINE = 1\n",
    "SHOULDER_CENTER = 2\n",
    "HEAD = 3\n",
    "SHOULDER_LEFT = 4\n",
    "ELBOW_LEFT = 5\n",
    "WRIST_LEFT = 6\n",
    "HAND_LEFT = 7\n",
    "SHOULDER_RIGHT = 8\n",
    "ELBOW_RIGHT = 9\n",
    "WRIST_RIGHT = 10\n",
    "HAND_RIGHT = 11\n",
    "HIP_LEFT = 12\n",
    "KNEE_LEFT = 13\n",
    "ANKLE_LEFT = 14\n",
    "FOOT_LEFT = 15\n",
    "HIP_RIGHT = 16\n",
    "KNEE_RIGHT = 17\n",
    "ANKLE_RIGHT = 18\n",
    "FOOT_RIGHT = 19\n",
    "\n",
    "nui_skeleton_names = ( \\\n",
    "    'HIP_CENTER', 'SPINE', 'SHOULDER_CENTER', 'HEAD', \\\n",
    "    'SHOULDER_LEFT', 'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', \\\n",
    "    'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT', \\\n",
    "    'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT', 'FOOT_LEFT', \\\n",
    "    'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT' )\n",
    "\n",
    "nui_skeleton_conn = ( \\\n",
    "    NONE, \\\n",
    "    HIP_CENTER, \\\n",
    "    SPINE, \\\n",
    "    SHOULDER_CENTER, \\\n",
    "    # Left arm \n",
    "    SHOULDER_CENTER, \\\n",
    "    SHOULDER_LEFT,  \\\n",
    "    ELBOW_LEFT,  \\\n",
    "    WRIST_LEFT,  \\\n",
    "    # Right arm \n",
    "    SHOULDER_CENTER,  \\\n",
    "    SHOULDER_RIGHT,  \\\n",
    "    ELBOW_RIGHT,  \\\n",
    "    WRIST_RIGHT,  \\\n",
    "    # Left leg \n",
    "    HIP_CENTER,  \\\n",
    "    HIP_LEFT,  \\\n",
    "    KNEE_LEFT,  \\\n",
    "    ANKLE_LEFT,  \\\n",
    "    # Right leg \n",
    "    HIP_CENTER,  \\\n",
    "    HIP_RIGHT,  \\\n",
    "    KNEE_RIGHT,  \\\n",
    "    ANKLE_RIGHT,  \\\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file=None):\n",
    "    \"\"\"\n",
    "      Returns the data, the labels and the person id for each action\n",
    "    \"\"\"\n",
    "    import scipy.io\n",
    "    \n",
    "    if file is None:\n",
    "        ex = scipy.io.loadmat('data/data.mat')\n",
    "    else:\n",
    "        ex = scipy.io.loadmat(file)\n",
    "        \n",
    "    return ex['data'],ex['labels'],ex['individuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normpdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "      Computes the natural logarithm of the normal probability density function\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    probs = np.empty((len(x),1))\n",
    "    for i in range(len(x)):\n",
    "        probs[i] =(scipy.stats.norm(mu[i], sigma[i]).logpdf(x[i]))\n",
    "    \n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_logprobs(log_probs):\n",
    "    \"\"\"\n",
    "       Returns the log prob normalizes so that when exponenciated\n",
    "       it adds up to 1 (Useful to normalizes logprobs)\n",
    "    \"\"\"\n",
    "    mm = np.max(log_probs)\n",
    "    return log_probs - mm - np.log(np.sum(np.exp(log_probs - mm)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gaussian(X, W=None):\n",
    "    \"\"\"\n",
    "      Compute the mean and variance of X, \n",
    "      You can ignore W for the moment\n",
    "    \"\"\"\n",
    "    mean=np.mean(X)\n",
    "    #variance=np.std(X)**2\n",
    "    #variance=np.var(X)\n",
    "    variance=np.std(X)\n",
    "    \n",
    "    return (mean, variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cov(x,y,w):\n",
    "    \"\"\"\n",
    "      Useful function for fit_linear_gaussian\n",
    "    \"\"\"\n",
    "    return np.sum(w*x*y)/np.sum(w)-np.sum(w*x)*np.sum(w*y)/np.sum(w)/np.sum(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_gaussian(Y,X,W = None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      Y: vector of size D with the observations for the variable\n",
    "      X: matrix DxV with the observations for the parent variables\n",
    "                 of X. V is the number of parent variables\n",
    "      W: vector of size D with the weights of the instances (ignore for the moment)\n",
    "      \n",
    "    Outout:\n",
    "       The betas and sigma\n",
    "    \"\"\"\n",
    "    # row = D = number of observations\n",
    "    # col = V = number of parents\n",
    "    [row,col] = X.shape\n",
    "    \n",
    "    A = np.ones((col+1, col+1))\n",
    "    B = np.empty((col+1, 1))\n",
    "    \n",
    "    B[0] = np.mean(Y[:])\n",
    "\n",
    "    for k in range (col):\n",
    "        A[0,k+1] = np.mean(X[:,k])\n",
    "        A[k+1,0] = np.mean(X[:,k])\n",
    "        B[k+1] = np.mean(Y[:]*X[:,k])\n",
    "\n",
    "    for i in range (col):\n",
    "        for j in range (col):\n",
    "            A[i+1,j+1] = np.mean(X[:,i]*X[:,j])\n",
    "    \n",
    "    betas = np.linalg.solve(A,B)\n",
    "    temp = 0\n",
    "    \n",
    "    for i in range (col):\n",
    "        for j in range (col):\n",
    "            temp = temp + betas[i+1]*betas[j+1]*(np.mean(X[:,i]*X[:,j]) - np.mean(X[:,i])*np.mean(X[:,j]))\n",
    "\n",
    "    sigma = math.sqrt(np.mean(Y[:]*Y[:]) - np.mean(Y[:])*np.mean(Y[:]) - temp)\n",
    "\n",
    "    \n",
    "\n",
    "    return (betas,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(model, dataset, labels, G):\n",
    "        model.connectivity = G\n",
    "        # initialize\n",
    "        model.class_priors = []\n",
    "        model.jointparts = [] \n",
    "        # fill\n",
    "        model.set_class_priors(labels)\n",
    "        model.set_jointparts(dataset, labels, G)\n",
    "    \n",
    "    def set_class_priors(model, labels):\n",
    "        nb_classes=len(np.unique(labels))\n",
    "        for class_nb in range(nb_classes):\n",
    "            model.class_priors.append(len(np.where(labels==class_nb))/len(labels))\n",
    "        \n",
    "    def set_jointparts(model, dataset, labels, G):\n",
    "        [r, c, d]=dataset.shape\n",
    "        # Create a list of joints\n",
    "        for joint in range(r):\n",
    "            model.jointparts.append(JointPart(dataset, labels, G, joint))\n",
    "            \n",
    "    def isNaiveBayes(model):\n",
    "        if model.connectivity==None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "              \n",
    "    \n",
    "\n",
    "class JointPart:\n",
    "    \n",
    "\n",
    "    def __init__(jointpart, dataset, labels, G, joint):\n",
    "        # initiaization\n",
    "        jointpart.joint_nb=joint\n",
    "        jointpart.means = []\n",
    "        jointpart.betas = []\n",
    "        jointpart.sigma = []\n",
    "        # fill depending on G\n",
    "        if G==None :\n",
    "            jointpart.fill_Naive_Bayes(dataset[jointpart.joint_nb, :, :], labels)\n",
    "        else:\n",
    "            jointpart.fill_Linear_Gaussian(dataset, labels, G)\n",
    "    \n",
    "    def fill_Naive_Bayes(jointpart, joint_dataset, labels):\n",
    "        [r, c]=joint_dataset.shape\n",
    "        \n",
    "        # Get all the different the classes, ordered : [1, 2, 3, 8]\n",
    "        classes=np.unique(labels)\n",
    "        \n",
    "        # Get the number of classes\n",
    "        nb_classes=len(classes)\n",
    "        \n",
    "        # Initialize means and sigma\n",
    "        jointpart.means = np.zeros((3, nb_classes))\n",
    "        jointpart.sigma = np.zeros((3, nb_classes))\n",
    "        \n",
    "        for pos in range(r): # x, y, z\n",
    "            for class_nb in range(nb_classes): # 1, 2, 3, 8\n",
    "                # Create mask of index of instances belonging to the class\n",
    "                mask_class=(labels==classes[class_nb])\n",
    "                mask_class=np.reshape(mask_class, (1, -1))\n",
    "                mask_class=mask_class.tolist()[0]\n",
    "                # get mean and variance\n",
    "                m, v = fit_gaussian(joint_dataset[pos, mask_class], W=None)\n",
    "                jointpart.means[pos, class_nb]=m\n",
    "                jointpart.sigma[pos, class_nb]=v\n",
    "      \n",
    "  \n",
    "    def fill_Linear_Gaussian(jointpart, dataset, labels, G):\n",
    "        \n",
    "        # Get all the different the classes, ordered : [1, 2, 3, 8]\n",
    "        classes=np.unique(labels)\n",
    "        \n",
    "        # Get the number of classes\n",
    "        nb_classes=len(classes)\n",
    "        \n",
    "        # Initialize betas and sigma\n",
    "        jointpart.betas = np.zeros((12, nb_classes))\n",
    "        jointpart.sigma = np.zeros((3, nb_classes))\n",
    "        \n",
    "        # dataset for that specific joint\n",
    "        joint_dataset=dataset[jointpart.joint_nb, :, :]\n",
    "        \n",
    "        [r, c]=joint_dataset.shape\n",
    "        \n",
    "        has_parent=True\n",
    "        \n",
    "        parent=G[jointpart.joint_nb]\n",
    "        \n",
    "        if parent!=-1:\n",
    "            parent_dataset=dataset[parent, :, :]\n",
    "        else:\n",
    "            has_parent=False\n",
    "        \n",
    "        for pos in range(r): # x, y, z\n",
    "            \n",
    "            for class_nb in range(nb_classes): # 1, 2, 3, 8\n",
    "                \n",
    "                # Create mask of index of instances belonging to the class\n",
    "                    mask_class=(labels==classes[class_nb])\n",
    "                    mask_class=np.reshape(mask_class, (1, -1))\n",
    "                    mask_class=mask_class.tolist()[0]\n",
    "                \n",
    "                    if has_parent:\n",
    "\n",
    "                        # get mean and variance\n",
    "                        b, s = fit_linear_gaussian(joint_dataset[pos, mask_class],np.transpose(parent_dataset[:, mask_class]), W = None)    \n",
    "                        b=np.reshape(b, (1, -1))\n",
    "                        b=b.tolist()[0]\n",
    "                        jointpart.betas[pos*4:pos*4+4, class_nb]=b\n",
    "                        jointpart.sigma[pos, class_nb]=s\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # if not, we fill betas with Naïve Bayes : fit_gaussian\n",
    "                        m, v = fit_gaussian(joint_dataset[pos, mask_class], W=None)\n",
    "                        jointpart.betas[pos*4:pos*4+4, class_nb]=m\n",
    "                        jointpart.sigma[pos, class_nb]=v\n",
    " \n",
    "\n",
    "    def isNaiveBayes(self):\n",
    "        if len(jointparts.betas)==0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(dataset, labels, G=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "     dataset: The data as it is loaded from load_data\n",
    "     labels:  The labels as loaded from load_data\n",
    "     Graph:   (optional) If None, this def should compute the naive \n",
    "           bayes model. If it contains a skel description (pe \n",
    "           nui_skeleton_conn, as obtained from skel_model) then it should\n",
    "           compute the model using the Linear Gausian Model\n",
    "\n",
    "    Output: the model\n",
    "     a (tentative) structure for the output model is:\n",
    "       model.connectivity: the input Graph variable should be stored here \n",
    "                           for later use.\n",
    "       model.class_priors: containing a vector with the prior estimations\n",
    "                           for each class\n",
    "       model.jointparts[i] contains the estimated parameters for the i-th joint\n",
    "\n",
    "          For joints that only depend on the class model.jointparts(i) has:\n",
    "            model.jointparts(i).means: a matrix of 3 x #classes with the\n",
    "                   estimated means for each of the x,y,z variables of the \n",
    "                   i-th joint and for each class.\n",
    "            model.jointparts(i).sigma: a matrix of 3 x #classes with the\n",
    "                   estimated stadar deviations for each of the x,y,z \n",
    "                   variables of the i-th joint and for each class.\n",
    "\n",
    "          For joints that follow a gausian linear model model.jointparts(i) has:\n",
    "            model.jointparts(i).betas: a matrix of 12 x #classes with the\n",
    "                   estimated betas for each x,y,z variables (12 in total) \n",
    "                   of the i-th joint and for each class label.\n",
    "            model.jointparts(i).sigma: as above\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Everything is set in the class\n",
    "    \n",
    "    model=Model(dataset, labels, G)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_instances(instances, model):\n",
    "    \"\"\"    \n",
    "    Input\n",
    "       instance: a 20x3x#instances matrix defining body positions of\n",
    "                 instances\n",
    "       model: as the output of learn_model\n",
    "\n",
    "    Output\n",
    "       probs: a matrix of #instances x #classes with the probability of each\n",
    "              instance of belonging to each of the classes\n",
    "\n",
    "    Important: to avoid underflow numerical issues this computations should\n",
    "               be performed in log space\n",
    "    \"\"\"\n",
    "    \n",
    "    classes_num = len(model.class_priors) \n",
    "    \n",
    "    if len(instances.shape)==2:\n",
    "        joints_num, coordinates_num = instances.shape\n",
    "        instances_num=1  \n",
    "    else:\n",
    "        joints_num, coordinates_num, instances_num= instances.shape\n",
    "        \n",
    "    \n",
    "    probs = np.zeros((instances_num, classes_num))\n",
    "    \n",
    "    if instances_num==1:\n",
    "        probs = compute_logprobs(instances,model)\n",
    "    else:    \n",
    "        for instance in range(instances_num):\n",
    "            probs[instance,:] = compute_logprobs(instances[:,:,instance],model)\n",
    "\n",
    "    return np.exp(probs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprobs(instance, model):\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "       Input\n",
    "           instance: a 20x3 matrix defining body positions of one instance\n",
    "           model: as given by learn_model\n",
    "\n",
    "       Output\n",
    "           l: a vector of len #classes containing the loglikelihhod of the \n",
    "              instance\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    joints_num, coordinates_num = instance.shape #here we get the 20*3 matrix of one instance\n",
    "    classes_num = len(model.class_priors) #here we get the number of classes in the model\n",
    "    logprobs = np.empty((classes_num,1))\n",
    "        \n",
    "        \n",
    "    if model.connectivity == None:\n",
    "\n",
    "        for each_class in range(classes_num):\n",
    "            product = math.log(model.class_priors[each_class]) # prior\n",
    "            for each_joint in range(joints_num): #sum up for all the joints\n",
    "                # sum up for three coordinates for each joint\n",
    "                product += sum(log_normpdf(instance[each_joint,:], model.jointparts[each_joint].means[:, each_class], model.jointparts[each_joint].sigma[:, each_class])) \n",
    "            logprobs[each_class] = product\n",
    "\n",
    "        logprobs = list(normalize_logprobs(logprobs) )\n",
    "\n",
    "\n",
    "    else:\n",
    "        for each_class in range(classes_num):\n",
    "            \n",
    "            product = math.log(model.class_priors[each_class]) # prior\n",
    "            \n",
    "            for each_joint in range(joints_num): #sum up for all the joints\n",
    "                means = []\n",
    "\n",
    "                for each_coordinate in range(coordinates_num):# mu = beta0 + beta1*parent1 +beta2*parent2 + beta3+parent3 \n",
    "                    \n",
    "                    if model.connectivity[each_joint] == -1:\n",
    "                        means.append(model.jointparts[each_joint].betas[each_coordinate*4,each_class])\n",
    "                                                            \n",
    "                    else :\n",
    "                        temp_mean = model.jointparts[each_joint].betas[each_coordinate*4,each_class] + model.jointparts[each_joint].betas[each_coordinate*4+1,each_class]*instance[model.connectivity[each_joint],0] + model.jointparts[each_joint].betas[each_coordinate*4+2,each_class]*instance[model.connectivity[each_joint],1] + model.jointparts[each_joint].betas[each_coordinate*4+3,each_class]*instance[model.connectivity[each_joint],2]\n",
    "                        means.append(temp_mean)\n",
    "  \n",
    "                product += sum(log_normpdf(instance[each_joint,:], means, model.jointparts[each_joint].sigma[:, each_class]))  #sum for all the 20 joints \n",
    "\n",
    "            logprobs[each_class] = product #the probability of a specific class\n",
    "        \n",
    "    \n",
    "    logprobs = list(normalize_logprobs(logprobs))\n",
    "\n",
    "    \n",
    "    return logprobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_lgm_samples(n, betas, sigma):\n",
    "    \"\"\"Function to generate random samples for a \n",
    "       Linear Gaussian Model\n",
    "       Input:\n",
    "           n: Number of samples\n",
    "           betas: vector with the values the the betas from 0 to k\n",
    "           sigma: standard deviation\n",
    "    \"\"\"\n",
    "    X = np.random.randn(n,betas.shape[0]-1)\n",
    "    Y = np.random.randn(n)*sigma + np.sum(X*betas[1:],axis=1)+betas[0]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(classified_instances, possible_classes):\n",
    "    label_pred=np.argmax(classified_instances, axis=1)\n",
    "    #label_pred=np.reshape(label_pred, (-1, 1))\n",
    "    for i in range (len(label_pred)):\n",
    "        label_pred[i]=possible_classes[label_pred[i]]\n",
    "    return label_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    y_pred=np.reshape(y_pred, y_true.shape)\n",
    "    return np.sum(y_pred == y_true)/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST FIT_LINEAR_GAUSSIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.00240848],\n",
       "        [1.99273976],\n",
       "        [9.97807045],\n",
       "        [3.99790738],\n",
       "        [4.98971808],\n",
       "        [6.01638476]]),\n",
       " 0.10179678344885083)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = np.array([1,2,10,4,5,6])\n",
    "sigma = 0.1\n",
    "n=100\n",
    "X,Y=generate_random_lgm_samples(n,betas,sigma)\n",
    "# This following call should output  betas and sigma close to the above ones\n",
    "fit_linear_gaussian(Y,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, individuals = load_dataset(file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_classes=np.unique(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST ON VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST 2 ###\n",
    "\n",
    "d = scipy.io.loadmat('data/validation_data.mat')\n",
    "\n",
    "data_small        = d['data_small']\n",
    "labels_small      = d['labels_small'].squeeze()\n",
    "individuals_small = d['individuals_small'].squeeze()\n",
    "#train_indexes     = np.array(d['train_indexes'].squeeze(),dtype=bool)\n",
    "#test_indexes      = np.array(d['test_indexes'].squeeze(),dtype=bool)\n",
    "#model_nb          = d['model_nb']\n",
    "#model_lg          = d['model_lg']\n",
    "#accur_lg          = d['accur_lg']\n",
    "#accur_nb          = d['accur_nb']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST ON VALIDATION DATA : Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params of following model should be similar to those of model_nb above\n",
    "naive_bayes_model = learn_model(data_small[:,:,train_indexes],labels_small[train_indexes])\n",
    "\n",
    "# Params of following model should be similar to those of model_lg above\n",
    "#  \n",
    "#  Note1: The implementation used to get model_lg stored the variance\n",
    "#  Note2: The implementation used to get model_lg added a epsilon to the \n",
    "#         variance to avoid numerical issues. Specifically the code at \n",
    "#         the end of fit_linear_gaussian used is:\n",
    "#\n",
    "#    sigma = np.sqrt(sigma)                                                       \n",
    "#                                                                                 \n",
    "#    if sigma == 0 or type(sigma) == 'complex':                                   \n",
    "#        sigma = .01                                                              \n",
    "#    else:                                                                        \n",
    "#        sigma = sigma + .01                                                      \n",
    "#                                                                                 \n",
    "#    sigma = sigma**2                                                             \n",
    "#                                                                                 \n",
    "#    return (betas,sigma) \n",
    "#\n",
    "\n",
    "# The accuracy of naive_bayes_model on data_small[:,:,test_indexes] that have labels\n",
    "# labels_small[test_indexes] should be aprox accur_nb\n",
    "nb_prob = classify_instances(data_small[:,:,test_indexes], naive_bayes_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb=predict_label(nb_prob, possible_classes)\n",
    "print(accuracy(y_pred_nb, labels_small[test_indexes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95]]\n"
     ]
    }
   ],
   "source": [
    "print(accur_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0165528  -0.02337965 -0.0247925  -0.08551245]\n",
      " [ 0.18375145 -0.4245773   0.12681275  0.1400868 ]\n",
      " [ 2.83720545  2.86587695  2.840341    2.6486826 ]]\n"
     ]
    }
   ],
   "source": [
    "print(naive_bayes_model.jointparts[0].means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0165528  -0.02337965 -0.0247925  -0.08551245]\n",
      " [ 0.18375145 -0.4245773   0.12681275  0.1400868 ]\n",
      " [ 2.83720545  2.86587695  2.840341    2.6486826 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model_nb[0, 0][0][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the we get the same means and sigmas as model_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Model is validated\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "\n",
    "#check that our Naïve Bayes and model_nb are equivalent (compare means and sigma)\n",
    "for i in range(20):\n",
    "    if (naive_bayes_model.jointparts[i].means-model_nb[0, 0][0][0][i][0]>1e-10).any() or (naive_bayes_model.jointparts[i].sigma-model_nb[0, 0][0][0][i][1]>1e-10).any():\n",
    "        c=c+1\n",
    "\n",
    "if c:\n",
    "    print(\"Naïve Bayes Model is not validated\")\n",
    "else:\n",
    "    print(\"Naïve Bayes Model is validated\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same means and sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST ON VALIDATION DATA : Linear Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_gaussian_model = learn_model(data_small[:,:,train_indexes],labels_small[train_indexes], nui_skeleton_conn)\n",
    "\n",
    "# The accuracy of linear_gaussian_model on data_small[:,:,test_indexes] that have labels\n",
    "# labels_small[test_indexes] should be aprox accur_lg\n",
    "lg_prob = classify_instances(data_small[:,:,test_indexes], linear_gaussian_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_lg=predict_label(lg_prob, possible_classes)\n",
    "print(accuracy(y_pred_lg, labels_small[test_indexes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.975]]\n"
     ]
    }
   ],
   "source": [
    "print(accur_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the we get the same betas and sigmas as model_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Gaussian Model is validated\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "\n",
    "#check that our Linear Gaussian Model and model_lg are equivalent (compare means and sigma) (1e-10)\n",
    "for i in range(2,20):\n",
    "    if (linear_gaussian_model.jointparts[i].betas-model_lg[0, 0][0][0][i][0]>1e-10).any() or (linear_gaussian_model.jointparts[i].sigma-model_lg[0, 0][0][0][i][1]>1e-10).any():\n",
    "        c=c+1\n",
    "\n",
    "if c:\n",
    "    print(\"Linear Gaussian Model is not validated\")\n",
    "else:\n",
    "    print(\"Linear Gaussian Model is validated\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same betas and sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING MODELS on the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING MODELS on the whole dataset : Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model=learn_model(data, labels, G=None)\n",
    "predictions_probs=classify_instances(data, nb_model)\n",
    "y_pred=predict_label(predictions_probs, possible_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525672371638142"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 92 , y_pred= 8  and y_true= [1]\n",
      "i= 93 , y_pred= 8  and y_true= [1]\n",
      "i= 94 , y_pred= 8  and y_true= [1]\n",
      "i= 95 , y_pred= 8  and y_true= [1]\n",
      "i= 96 , y_pred= 8  and y_true= [1]\n",
      "i= 97 , y_pred= 8  and y_true= [1]\n",
      "i= 98 , y_pred= 8  and y_true= [1]\n",
      "i= 99 , y_pred= 8  and y_true= [1]\n",
      "i= 100 , y_pred= 8  and y_true= [1]\n",
      "i= 101 , y_pred= 8  and y_true= [1]\n",
      "i= 408 , y_pred= 3  and y_true= [1]\n",
      "i= 409 , y_pred= 3  and y_true= [1]\n",
      "i= 426 , y_pred= 8  and y_true= [1]\n",
      "i= 428 , y_pred= 8  and y_true= [1]\n",
      "i= 429 , y_pred= 8  and y_true= [1]\n",
      "i= 430 , y_pred= 8  and y_true= [1]\n",
      "i= 434 , y_pred= 8  and y_true= [1]\n",
      "i= 435 , y_pred= 8  and y_true= [1]\n",
      "i= 446 , y_pred= 8  and y_true= [1]\n",
      "i= 447 , y_pred= 8  and y_true= [1]\n",
      "i= 448 , y_pred= 8  and y_true= [1]\n",
      "i= 449 , y_pred= 8  and y_true= [1]\n",
      "i= 450 , y_pred= 8  and y_true= [1]\n",
      "i= 451 , y_pred= 8  and y_true= [1]\n",
      "i= 452 , y_pred= 8  and y_true= [1]\n",
      "i= 453 , y_pred= 8  and y_true= [1]\n",
      "i= 454 , y_pred= 8  and y_true= [1]\n",
      "i= 480 , y_pred= 3  and y_true= [1]\n",
      "i= 1073 , y_pred= 8  and y_true= [3]\n",
      "i= 1075 , y_pred= 8  and y_true= [3]\n",
      "i= 1154 , y_pred= 8  and y_true= [3]\n",
      "i= 1155 , y_pred= 8  and y_true= [3]\n",
      "i= 1156 , y_pred= 8  and y_true= [3]\n",
      "i= 1157 , y_pred= 8  and y_true= [3]\n",
      "i= 1158 , y_pred= 8  and y_true= [3]\n",
      "i= 1159 , y_pred= 8  and y_true= [3]\n",
      "i= 1160 , y_pred= 8  and y_true= [3]\n",
      "i= 1161 , y_pred= 8  and y_true= [3]\n",
      "i= 1162 , y_pred= 8  and y_true= [3]\n",
      "i= 1163 , y_pred= 8  and y_true= [3]\n",
      "i= 1186 , y_pred= 8  and y_true= [3]\n",
      "i= 1187 , y_pred= 8  and y_true= [3]\n",
      "i= 1188 , y_pred= 8  and y_true= [3]\n",
      "i= 1189 , y_pred= 8  and y_true= [3]\n",
      "i= 1190 , y_pred= 8  and y_true= [3]\n",
      "i= 1191 , y_pred= 8  and y_true= [3]\n",
      "i= 1192 , y_pred= 8  and y_true= [3]\n",
      "i= 1193 , y_pred= 8  and y_true= [3]\n",
      "i= 1194 , y_pred= 8  and y_true= [3]\n",
      "i= 1195 , y_pred= 8  and y_true= [3]\n",
      "i= 1209 , y_pred= 8  and y_true= [3]\n",
      "i= 1212 , y_pred= 8  and y_true= [3]\n",
      "i= 1213 , y_pred= 8  and y_true= [3]\n",
      "i= 1214 , y_pred= 8  and y_true= [3]\n",
      "i= 1215 , y_pred= 8  and y_true= [3]\n",
      "i= 1216 , y_pred= 8  and y_true= [3]\n",
      "i= 1230 , y_pred= 8  and y_true= [3]\n",
      "i= 1232 , y_pred= 8  and y_true= [3]\n",
      "i= 1235 , y_pred= 8  and y_true= [3]\n",
      "i= 1292 , y_pred= 8  and y_true= [3]\n",
      "i= 1293 , y_pred= 8  and y_true= [3]\n",
      "i= 1294 , y_pred= 8  and y_true= [3]\n",
      "i= 1295 , y_pred= 8  and y_true= [3]\n",
      "i= 1296 , y_pred= 8  and y_true= [3]\n",
      "i= 1297 , y_pred= 8  and y_true= [3]\n",
      "i= 1298 , y_pred= 8  and y_true= [3]\n",
      "i= 1469 , y_pred= 8  and y_true= [3]\n",
      "i= 1470 , y_pred= 8  and y_true= [3]\n",
      "i= 1471 , y_pred= 8  and y_true= [3]\n",
      "i= 1472 , y_pred= 8  and y_true= [3]\n",
      "i= 1473 , y_pred= 8  and y_true= [3]\n",
      "i= 1474 , y_pred= 8  and y_true= [3]\n",
      "i= 1475 , y_pred= 8  and y_true= [3]\n",
      "i= 1476 , y_pred= 8  and y_true= [3]\n",
      "i= 1477 , y_pred= 8  and y_true= [3]\n",
      "i= 1478 , y_pred= 8  and y_true= [3]\n",
      "i= 1728 , y_pred= 3  and y_true= [8]\n",
      "i= 1729 , y_pred= 3  and y_true= [8]\n",
      "i= 1730 , y_pred= 3  and y_true= [8]\n",
      "i= 1731 , y_pred= 3  and y_true= [8]\n",
      "i= 1732 , y_pred= 3  and y_true= [8]\n",
      "i= 1733 , y_pred= 3  and y_true= [8]\n",
      "i= 1734 , y_pred= 3  and y_true= [8]\n",
      "i= 1735 , y_pred= 3  and y_true= [8]\n",
      "i= 1736 , y_pred= 3  and y_true= [8]\n",
      "i= 1941 , y_pred= 3  and y_true= [8]\n",
      "i= 1942 , y_pred= 3  and y_true= [8]\n",
      "i= 2005 , y_pred= 3  and y_true= [8]\n",
      "i= 2006 , y_pred= 3  and y_true= [8]\n",
      "i= 2007 , y_pred= 3  and y_true= [8]\n",
      "i= 2008 , y_pred= 3  and y_true= [8]\n",
      "i= 2009 , y_pred= 3  and y_true= [8]\n",
      "i= 2010 , y_pred= 3  and y_true= [8]\n",
      "i= 2011 , y_pred= 3  and y_true= [8]\n",
      "i= 2012 , y_pred= 3  and y_true= [8]\n",
      "i= 2013 , y_pred= 3  and y_true= [8]\n",
      "i= 2014 , y_pred= 3  and y_true= [8]\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(y_pred)):  \n",
    "    if y_pred[i]!=labels[i]:\n",
    "        print (\"i=\", i, \", y_pred=\", y_pred[i], \" and y_true=\", labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[480,   0,   3,  25],\n",
       "       [  0, 500,   0,   0],\n",
       "       [  0,   0, 474,  48],\n",
       "       [  0,   0,  21, 494]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING MODELS on the whole dataset : Linear Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model=learn_model(data, labels, nui_skeleton_conn)\n",
    "lg_predictions_probs=classify_instances(data, lg_model)\n",
    "lg_y_pred=predict_label(lg_predictions_probs, possible_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921760391198045"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(lg_y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[493,   0,   0,  15],\n",
       "       [  0, 500,   0,   0],\n",
       "       [  0,   0, 521,   1],\n",
       "       [  0,   0,   0, 515]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels, lg_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN and VALIDATION datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_prob_val=classify_instances(data_small, nb_model)\n",
    "NB_y_pred_val=predict_label(NB_prob_val, possible_classes)\n",
    "accuracy(NB_y_pred_val, labels_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0,  1],\n",
       "       [ 0, 30,  0,  0],\n",
       "       [ 0,  0, 28,  2],\n",
       "       [ 0,  0,  2, 28]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels_small, NB_y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LG_prob_val=classify_instances(data_small, lg_model)\n",
    "LG_y_pred_val=predict_label(LG_prob_val, possible_classes)\n",
    "accuracy(LG_y_pred_val, labels_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30,  0,  0,  0],\n",
       "       [ 0, 30,  0,  0],\n",
       "       [ 0,  0, 30,  0],\n",
       "       [ 0,  0,  0, 30]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels_small, LG_y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN/TEST SET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.arange(len(labels))\n",
    "training_indices=indices%3>0\n",
    "test_indices=indices%3==0\n",
    "\n",
    "training_data=data[:,:,training_indices]\n",
    "training_labels=labels[training_indices]\n",
    "test_data=data[:,:,test_indices]\n",
    "test_labels=labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3, 1363)\n",
      "1363\n",
      "(20, 3, 682)\n",
      "682\n"
     ]
    }
   ],
   "source": [
    "print(training_data.shape)\n",
    "print(len(training_labels))\n",
    "print(test_data.shape)\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472140762463344"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NB=learn_model(training_data, training_labels, G=None)\n",
    "NB_predictions_probs=classify_instances(test_data, model_NB)\n",
    "y_pred_NB=predict_label(NB_predictions_probs, possible_classes)\n",
    "accuracy(y_pred_NB, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158,   0,   2,  10],\n",
       "       [  0, 166,   0,   0],\n",
       "       [  0,   0, 157,  17],\n",
       "       [  0,   0,   7, 165]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(test_labels, y_pred_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868035190615836"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LG=learn_model(training_data, training_labels, nui_skeleton_conn)\n",
    "LG_predictions_probs=classify_instances(test_data, model_LG)\n",
    "y_pred_LG=predict_label(LG_predictions_probs, possible_classes)\n",
    "accuracy(y_pred_LG, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162,   0,   0,   8],\n",
       "       [  0, 166,   0,   0],\n",
       "       [  0,   0, 173,   1],\n",
       "       [  0,   0,   0, 172]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(test_labels, y_pred_LG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, labels, k, G):\n",
    "    nb_instances=len(labels)\n",
    "    k_percent=math.floor(nb_instances/k)\n",
    "    indices=np.arange(nb_instances)\n",
    "    np.random.shuffle(indices)\n",
    "    shuffled_indices =  indices\n",
    "    possible_classes=np.unique(labels)\n",
    "    \n",
    "    models=[]\n",
    "    accuracies=[]\n",
    "\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        training_indices=shuffled_indices[k_percent*i:k_percent*i+k_percent]\n",
    "        test_indices=np.concatenate((shuffled_indices[:k_percent*i], shuffled_indices[k_percent*i+k_percent:]), axis=None)\n",
    "        #test_indices=shuffled_indices[:k_percent*i].append(shuffled_indices[k_percent*i+k_percent:])\n",
    "        training_data=data[:,:,training_indices]\n",
    "        training_labels=labels[training_indices]\n",
    "        test_data=data[:,:,test_indices]\n",
    "        test_labels=labels[test_indices]\n",
    "        \n",
    "        models.append(learn_model(training_data, training_labels, G))\n",
    "        prob=classify_instances(test_data, models[i])\n",
    "        y_pred=predict_label(prob, possible_classes)\n",
    "        accuracies.append(accuracy(y_pred, test_labels))\n",
    "        print(\"accuracy : \",accuracies[i])\n",
    "        \n",
    "    \n",
    "    return models, accuracies\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "accuracy :  0.9750135795763172\n",
      "1\n",
      "accuracy :  0.9440521455730582\n",
      "2\n",
      "accuracy :  0.9272134709397066\n",
      "3\n",
      "accuracy :  0.9359043997827268\n",
      "4\n",
      "accuracy :  0.9755567626290059\n",
      "5\n",
      "accuracy :  0.9304725692558392\n",
      "6\n",
      "accuracy :  0.9293862031504617\n",
      "7\n",
      "accuracy :  0.9429657794676806\n",
      "8\n",
      "accuracy :  0.9424225964149918\n",
      "9\n",
      "accuracy :  0.9565453557848995\n"
     ]
    }
   ],
   "source": [
    "models_nb, accuracies_nb=cross_validation(data, labels, 10, G=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "accuracy :  0.9891363389462249\n",
      "1\n",
      "accuracy :  0.9885931558935361\n",
      "2\n",
      "accuracy :  0.9918522542096686\n",
      "3\n",
      "accuracy :  0.9853340575774036\n",
      "4\n",
      "accuracy :  0.9815317762085823\n",
      "5\n",
      "accuracy :  0.9929386203150462\n",
      "6\n",
      "accuracy :  0.9831613253666486\n",
      "7\n",
      "accuracy :  0.9842476914720261\n",
      "8\n",
      "accuracy :  0.986420423682781\n",
      "9\n",
      "accuracy :  0.9853340575774036\n"
     ]
    }
   ],
   "source": [
    "models_lg, accuracies_lg=cross_validation(data, labels, 10, nui_skeleton_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the best NB model\n",
    "\n",
    "model_nb=models_nb[np.argmax(accuracies_nb)]\n",
    "prob_nb_val=classify_instances(data_small, model_nb)\n",
    "y_pred_nb_val=predict_label(prob_nb_val, np.unique(labels))\n",
    "accuracy(y_pred_nb_val, labels_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0,  1],\n",
       "       [ 0, 30,  0,  0],\n",
       "       [ 0,  0, 30,  0],\n",
       "       [ 0,  0,  1, 29]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels_small, y_pred_nb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the best  model\n",
    "\n",
    "model_lg=models_lg[np.argmax(accuracies_lg)]\n",
    "prob_lg_val=classify_instances(data_small, model_lg)\n",
    "y_pred_lg_val=predict_label(prob_lg_val, np.unique(labels))\n",
    "accuracy(y_pred_lg_val, labels_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30,  0,  0,  0],\n",
       "       [ 0, 30,  0,  0],\n",
       "       [ 0,  0, 30,  0],\n",
       "       [ 0,  0,  0, 30]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels_small, y_pred_lg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770171149144254"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PNB=classify_instances(data, model_nb)\n",
    "YPREDNB=predict_label(PNB, np.unique(labels))\n",
    "accuracy(YPREDNB, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[479,   0,   4,  25],\n",
       "       [  0, 500,   0,   0],\n",
       "       [  0,   0, 516,   6],\n",
       "       [  0,   0,  12, 503]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels, YPREDNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993643031784841"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PLG=classify_instances(data, model_lg)\n",
    "YPREDLG=predict_label(PLG, np.unique(labels))\n",
    "accuracy(YPREDLG, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[501,   0,   0,   7],\n",
       "       [  0, 500,   0,   0],\n",
       "       [  0,   0, 520,   2],\n",
       "       [  0,   0,   4, 511]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels, YPREDLG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
